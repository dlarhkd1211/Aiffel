{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 미니프로젝트 : 가위바위보 분류기 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('.\\\\data\\\\train\\\\paper\\\\0.jpg')\n",
    "img = np.array(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images = glob(img_path + '\\\\*.jpg')\n",
    "    \n",
    "    print(len(images))\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, 'JPEG')\n",
    "        \n",
    "    print(len(images), 'Images resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 Images resized\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path =\".\\\\data\\\\train\\\\scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 Images resized\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path =\".\\\\data\\\\train\\\\paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 Images resized\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path =\".\\\\data\\\\train\\\\rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(img_path, number_of_data = 300):\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    imgs = np.zeros(number_of_data * img_size * img_size * color, dtype = np.int32).reshape(number_of_data, img_size, img_size, color)\n",
    "    labels = np.zeros(number_of_data, dtype = np.int32)\n",
    "    \n",
    "    idx = 0\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    for file in glob(img_path + '\\\\scissor\\\\*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img\n",
    "        labels[idx] = 0\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob(img_path + '\\\\rock\\\\*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img\n",
    "        labels[idx] = 1\n",
    "        idx += 1\n",
    "        \n",
    "    for file in glob(img_path + '\\\\paper\\\\*.jpg'):\n",
    "        img = np.array(Image.open(file), dtype = np.int32)\n",
    "        imgs[idx,:,:,:] = img\n",
    "        labels[idx] = 2\n",
    "        idx += 1\n",
    "        \n",
    "    print('학습데이터의 이미지 개수는 ',idx,'입니다.')\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는  300 입니다.\n"
     ]
    }
   ],
   "source": [
    "img_dir_path = '.\\\\data\\\\train'\n",
    "x_train, y_train = load_data(img_dir_path)\n",
    "x_train_norm = x_train / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 24ms/step - loss: 1.0811 - accuracy: 0.3533\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.9840 - accuracy: 0.5533\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.8212 - accuracy: 0.6800\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.6032 - accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.3947 - accuracy: 0.9133\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2334 - accuracy: 0.9633\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1272 - accuracy: 0.9933\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0201 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28d8406f550>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_channel_1= 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 64\n",
    "n_train_epoch = 10\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(n_channel_1, (3, 3), activation = 'relu', input_shape = (28, 28, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(n_channel_2, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense, activation = 'relu'))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100 Images resized\n",
      "100\n",
      "100 Images resized\n",
      "100\n",
      "100 Images resized\n"
     ]
    }
   ],
   "source": [
    "image_dir_path =\".\\\\data\\\\test\\\\rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path =\".\\\\data\\\\test\\\\scissor\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path =\".\\\\data\\\\test\\\\paper\"\n",
    "resize_images(image_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터의 이미지 개수는  300 입니다.\n"
     ]
    }
   ],
   "source": [
    "test_dir_path = '.\\\\data\\\\test'\n",
    "x_test, y_test = load_data(test_dir_path)\n",
    "x_test_norm = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.8580 - accuracy: 0.5733\n",
      "test_loss : 1.858007550239563\n",
      "test_accuracy : 0.5733333230018616\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = model.evaluate(x_test_norm, y_test, verbose = 2)\n",
    "print('test_loss : {}'.format(test_loss))\n",
    "print('test_accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_1= 32\n",
    "n_channel_2 = 64\n",
    "n_channel_3 = 128\n",
    "n_dense_1 = 256\n",
    "n_dense_2 = 16\n",
    "n_train_epoch = 20\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Conv2D(n_channel_1, (3, 3), activation = 'relu', input_shape = (28, 28, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(n_channel_2, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(n_channel_3, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense_1, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_dense_2, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 9.9871 - accuracy: 0.3333\n",
      "test_loss : 9.987105369567871\n",
      "test_accuracy : 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = model.evaluate(x_test_norm, y_test, verbose = 2)\n",
    "print('test_loss : {}'.format(test_loss))\n",
    "print('test_accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0121 - accuracy: 1.0000\n",
      "test_loss : 0.012131466530263424\n",
      "test_accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss , test_accuracy = model.evaluate(x_train_norm, y_train, verbose = 2)\n",
    "print('test_loss : {}'.format(test_loss))\n",
    "print('test_accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
