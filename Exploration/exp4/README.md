## 회고록

비전 및 정형데이터를 주로 다뤄왔다 보니 개념에 대한 이해가 다른 exploration에 비해서는 조금 더 걸렸던것 같다.

RNN 연습하는 과정에서는 대본의 특성을 파악해 ':'가 마지막에 포함된 문자열을 제거해주었는데, 작사 인공지능 만드는 프로젝트에서는 [chorus] 라는 용어가 많이 나와 이를 제거해주었다.

또한, 루브릭 기준인 validation loss를 10 epoch만에 2.2 이하로 낮추기 위해 embedding size와 hidden size를 기존 연습 과정의 2배로 증가시켜주었다. 

RNN도 결국은 인공지능 모델 중 하나이고, 이를 사용하는 것은 CNN이라 다를 것이 별로 없었다. 그러나 전처리 부분은 완전히 다른 과정을 거친다. 이를 통해 데이터의 특성에 맞는 전처리가 인공지능의 핵심이라는 것을 다시한번 상기시킬 수 있는 기회가 되었다. 
