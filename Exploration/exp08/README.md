## 회고록

- seq2seq와 Attention Mechanism에 대해 처음 접하고 진행하다보니 이에 대한 이해를 하는 부분에 어려움이 있었다.

- 모델의 성능이 그럴듯한 요약문을 만들어주는 정도까지는 도달하지 못했는데 모델 구조를 비교적 간단하게 한 것이 어느정도 영향이 있지 않을까 싶다.

- 모델링을 통해 요약하는 방식만을 알고 있었는데, 원문에서 추출하여 요약하는 방식에 대해서는 처음 접해봐서 새로웠다. 이 방식에 대해서는 라이브러리도 끝난것이 아쉽긴 하다.

- 전처리 부분이 어느 데이터든 가장 중요하지만 텍스트데이터의 경우 더 어렵고 더 꼼꼼히 봐야할것 같다. 불용어나 정규화 등 여러가지 규칙들을 모두 고려해줘야 하기 때문이다.
